@article{kollias2021mia, title={MIA-COV19D: COVID-19 Detection through 3-D Chest CT Image Analysis}, author={Kollias, Dimitrios and Arsenos, Anastasios and Soukissian, Levon and Kollias, Stefanos}, journal={arXiv preprint arXiv:2106.07524}, year={2021}}

@article{kollias2020deep, title={Deep transparent prediction through latent representation analysis}, author={Kollias, Dimitrios and Bouas, N and Vlaxos, Y and Brillakis, V and Seferis, M and Kollia, Ilianna and Sukissian, Levon and Wingate, James and Kollias, S}, journal={arXiv preprint arXiv:2009.07044}, year={2020}}

@inproceedings{kollias2020transparent, title={Transparent Adaptation in Deep Medical Image Diagnosis.}, author={Kollias, Dimitris and Vlaxos, Y and Seferis, M and Kollia, Ilianna and Sukissian, Levon and Wingate, James and Kollias, Stefanos D}, booktitle={TAILOR}, pages={251–267}, year={2020}}

@article{kollias2018deep, title={Deep neural architectures for prediction in healthcare}, author={Kollias, Dimitrios and Tagaris, Athanasios and Stafylopatis, Andreas and Kollias, Stefanos and Tagaris, Georgios}, journal={Complex \& Intelligent Systems}, volume={4}, number={2}, pages={119–131}, year={2018}, publisher={Springer}}


@INPROCEEDINGS{Tran2018,
  author={Tran, Du and Wang, Heng and Torresani, Lorenzo and Ray, Jamie and LeCun, Yann and Paluri, Manohar},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  title={A Closer Look at Spatiotemporal Convolutions for Action Recognition}, 
  year={2018},
  volume={},
  number={},
  pages={6450-6459},
  doi={10.1109/CVPR.2018.00675}}

@misc{https://doi.org/10.48550/arxiv.1705.06950,
  doi = {10.48550/ARXIV.1705.06950},
  
  url = {https://arxiv.org/abs/1705.06950},
  
  author = {Kay, Will and Carreira, Joao and Simonyan, Karen and Zhang, Brian and Hillier, Chloe and Vijayanarasimhan, Sudheendra and Viola, Fabio and Green, Tim and Back, Trevor and Natsev, Paul and Suleyman, Mustafa and Zisserman, Andrew},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {The Kinetics Human Action Video Dataset},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{kollias2022ai, title={AI-MIA: COVID-19 Detection \& Severity Analysis through Medical Imaging}, author={Kollias, Dimitrios and Arsenos, Anastasios and Kollias, Stefanos}, journal={arXiv preprint arXiv:2206.04732}, year={2022}}

@article{peeling2022,
    author = "Peeling, Rosanna W and Heymann, David L and Teo, Yik-Ying and Garcia, Patricia J",
    type = "Journal Article; Review",
    title = "Diagnostics for COVID-19: moving from pandemic response to control.",
    journal = "Lancet (London, England)",
    date = "2022 Feb 19",
    volume = "399",
    pages = "757-768",
    issn = "1474-547X (Electronic); 0140-6736 (Print); 0140-6736 (Linking)",
    abstract = "Diagnostics have proven to be crucial to the COVID-19 pandemic response. Thereare three major methods for the detection of SARS-CoV-2 infection and their rolehas evolved during the course of the pandemic. Molecular tests such as PCR arehighly sensitive and specific at detecting viral RNA, and are recommended by WHOfor confirming diagnosis in individuals who are symptomatic and for activatingpublic health measures. Antigen rapid detection tests detect viral proteins and,although they are less sensitive than molecular tests, have the advantages ofbeing easier to do, giving a faster time to result, of being lower cost, and ableto detect infection in those who are most likely to be at risk of transmittingthe virus to others. Antigen rapid detection tests can be used as a public healthtool for screening individuals at enhanced risk of infection, to protect peoplewho are clinically vulnerable, to ensure safe travel and the resumption ofschooling and social activities, and to enable economic recovery. With vaccineroll-out, antibody tests (which detect the host's response to infection orvaccination) can be useful surveillance tools to inform public policy, but shouldnot be used to provide proof of immunity, as the correlates of protection remainunclear. All three types of COVID-19 test continue to have a crucial role in thetransition from pandemic response to pandemic control.",
    year = "2022",
    doi = "10.1016/S0140-6736(21)02346-1",
    pmid = "34942102",
    own = "NLM",
    stat = "MEDLINE",
    dcom = "20220301",
    lr = "20220301",
    ip = "10326",
    lid = "S0140-6736(21)02346-1 [pii]; 10.1016/S0140-6736(21)02346-1 [doi]",
    ci = "Copyright © 2022 Elsevier Ltd. All rights reserved.",
    au = "Peeling RW; Heymann DL; Teo YY; Garcia PJ",
    ad = "Clinical Research Department, London School of Hygiene \& Tropical Medicine,London, UK; Medical Microbiology Department, University of Manitoba, Winnipeg,Manitoba, Canada. Electronic address: rosanna.peeling@lshtm.ac.uk.; Clinical Research Department, London School of Hygiene \& Tropical Medicine,London, UK.; Saw Swee Hock School of Public Health, National University of Singapore,Singapore.; School of Public Health, Universidad Peruana Cayetano Heredia, Lima, Peru;Department of Global Health, University of Washington, Seattle, WA, USA.",
    la = "eng",
    dep = "20211220",
    ta = "Lancet",
    jid = "2985213R",
    rn = "0 (Antibodies, Viral); 0 (Antigens, Viral); 0 (COVID-19 Vaccines); 0 (RNA, Viral)",
    sb = "IM",
    mh = "Antibodies, Viral/blood; Antigens, Viral/isolation \& purification; COVID-19/*diagnosis/epidemiology/transmission/virology; COVID-19 Testing/methods/*trends; COVID-19 Vaccines/administration \& dosage; Communicable Disease Control/methods/*organization \& administration/trends; Humans; Mass Screening/*organization \& administration/trends; Pandemics/*prevention \& control; RNA, Viral/isolation \& purification; SARS-CoV-2/genetics/immunology/isolation \& purification",
    pmc = "PMC8687671",
    cois = "Declaration of interests We declare no competing interests.",
    edat = "2021/12/24 06:00",
    mhda = "2022/03/03 06:00",
    crdt = "2021/12/23 20:11",
    phst = "2021/05/03 00:00 [received]; 2021/10/06 00:00 [revised]; 2021/10/20 00:00 [accepted]; 2021/12/24 06:00 [pubmed]; 2022/03/03 06:00 [medline]; 2021/12/23 20:11 [entrez]",
    pst = "ppublish",
    so = "Lancet. 2022 Feb 19;399(10326):757-768. doi: 10.1016/S0140-6736(21)02346-1. Epub2021 Dec 20.",
    aid = "S0140-6736(21)02346-1 [pii]"
}

@misc{who2021,
  title = {{Recommendations for national SARS-CoV-2 testing strategies and diagnostic capacities}},
  howpublished = {\url{https://www.who.int/publications/i/item/WHO-2019-nCoV-lab-testing-2021.1-eng}},
  author = {{World Health Organization}},
  date = "2021 June 25",
  note = {Accessed: 2022-06-27}
}

@article{seeram2018,
    author = "Seeram, Euclid",
    type = "Journal Article; Review",
    title = "Computed Tomography: A Technical Review",
    journal = "Radiologic Technology",
    date = "2018 Jan",
    volume = "89",
    pages = "279CT-302CT",
    issn = "1943-5657 (Electronic); 0033-8397 (Linking)",
    abstract = "Computed tomography (CT) is a technical and complex diagnostic imaging modality.Radiologic technologists must understand the technology well enough to optimizedose and image quality and provide excellent patient care. This article reviewsessential physical principles and technical aspects of CT, including physicsrelated to radiation attenuation and CT numbers along with general technicalconcepts. In addition, the article reviews multislice CT technology.",
    year = "2018",
    pmid = "29298954",
    own = "NLM",
    stat = "MEDLINE",
    dcom = "20180914",
    lr = "20180914",
    ip = "3",
    ci = "© 2018 American Society of Radiologic Technologists.",
    au = "Seeram E",
    la = "eng",
    pl = "United States",
    ta = "Radiol Technol",
    jid = "0401256",
    sb = "IM",
    mh = "Humans; Imaging, Three-Dimensional; Physics; Radiation Dosage; Radiation Protection; Radiographic Image Interpretation, Computer-Assisted; Tomography, X-Ray Computed/instrumentation/*methods",
    edat = "2018/01/05 06:00",
    mhda = "2018/09/15 06:00",
    crdt = "2018/01/05 06:00",
    phst = "2018/01/05 06:00 [entrez]; 2018/01/05 06:00 [pubmed]; 2018/09/15 06:00 [medline]",
    pst = "ppublish",
    so = "Radiol Technol. 2018 Jan;89(3):279CT-302CT.",
    aid = "89/3/279CT [pii]"
}

@article{harmon2020,
    author = "Harmon, Stephanie A. and Sanford, Thomas H. and Xu, Sheng and Turkbey, Evrim B. and Roth, Holger and Xu, Ziyue and Yang, Dong and Myronenko, Andriy and Anderson, Victoria and Amalou, Amel and Blain, Maxime and Kassin, Michael and Long, Dilara and Varble, Nicole and Walker, Stephanie M. and Bagci, Ulas and Ierardi, Anna Maria and Stellato, Elvira and Plensich, Guido Giovanni and Franceschelli, Giuseppe and Girlando, Cristiano and Irmici, Giovanni and Labella, Dominic and Hammoud, Dima and Malayeri, Ashkan and Jones, Elizabeth and Summers, Ronald M. and Choyke, Peter L. and Xu, Daguang and Flores, Mona and Tamura, Kaku and Obinata, Hirofumi and Mori, Hitoshi and Patella, Francesca and Cariati, Maurizio and Carrafiello, Gianpaolo and An, Peng and Wood, Bradford J. and Turkbey, Baris",
    type = "Journal Article",
    title = "Artificial intelligence for the detection of COVID-19 pneumonia on chest CT using multinational datasets",
    journal = "Nature Communications",
    number = "1",
    doi = "10.1038/s41467-020-17971-2",
    volume = "11",
    pages = "4080",
    url = "https://doi.org/10.1038/s41467-020-17971-2",
    year = "2020",
    abstract = "Chest CT is emerging as a valuable diagnostic tool for clinical management of COVID-19 associated lung disease. Artificial intelligence (AI) has the potential to aid in rapid evaluation of CT scans for differentiation of COVID-19 findings from other clinical entities. Here we show that a series of deep learning algorithms, trained in a diverse multinational cohort of 1280 patients to localize parietal pleura/lung parenchyma followed by classification of COVID-19 pneumonia, can achieve up to 90.8\% accuracy, with 84\% sensitivity and 93\% specificity, as evaluated in an independent test set (not included in training and validation) of 1337 patients. Normal controls included chest CTs from oncology, emergency, and pneumonia-related indications. The false positive rate in 140 patients with laboratory confirmed other (non COVID-19) pneumonias was 10\%. AI-based algorithms can readily identify CT scans with COVID-19 associated pneumonia, as well as distinguish non-COVID related pneumonias with high specificity in diverse patient populations.",
    issn = "2041-1723",
    da = "2020/08/14"
}

@article{doi:10.1148/radiol.2020200343,
author = {Xie, Xingzhi and Zhong, Zheng and Zhao, Wei and Zheng, Chao and Wang, Fei and Liu, Jun},
title = {{Chest CT for Typical Coronavirus Disease 2019 (COVID-19) Pneumonia:                     Relationship to Negative RT-PCR Testing}},
journal = {Radiology},
volume = {296},
number = {2},
pages = {E41-E45},
year = {2020},
doi = {10.1148/radiol.2020200343},
    note ={PMID: 32049601},

URL = { 
        https://doi.org/10.1148/radiol.2020200343
    
},
eprint = { 
        https://doi.org/10.1148/radiol.2020200343
    
}
,
    abstract = { Some patients with positive chest CT findings may present with negative results of real-time reverse-transcription polymerase chain reaction (RT-PCR) tests for coronavirus disease 2019 (COVID-19). In this study, the authors present chest CT findings from five patients with COVID-19 infection who had initial negative RT-PCR results. All five patients had typical imaging findings, including ground-glass opacity (five patients) and/or mixed ground-glass opacity and mixed consolidation (two patients). After isolation for presumed COVID-19 pneumonia, all patients were eventually confirmed to have COVID-19 infection by means of repeated swab tests. A combination of repeated swab tests and CT scanning may be helpful for individuals with a high clinical suspicion of COVID-19 infection but negative findings at RT-PCR screening. © RSNA, 2020 }
}


@INPROCEEDINGS{Hou2021,
  author={Hou, Junlin and Xu, Jilan and Feng, Rui and Zhang, Yuejie and Shan, Fei and Shi, Weiya},
  booktitle={2021 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)}, 
  title={CMC-COV19D: Contrastive Mixup Classification for COVID-19 Diagnosis}, 
  year={2021},
  volume={},
  number={},
  pages={454-461},
  doi={10.1109/ICCVW54120.2021.00055}
 }
 
 @article{Miron2021COVIDDI,
  title={{COVID Detection in Chest CTs: Improving the Baseline on COV19-CT-DB}},
  author={Radu Miron and Cosmin Moisii and Sergiu-Andrei Dinu and Mihaela Breaban},
  journal={ArXiv},
  year={2021},
  volume={abs/2107.04808}
}

@incollection{NEURIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@Article{fastai2,
AUTHOR = {Howard, Jeremy and Gugger, Sylvain},
TITLE = {{Fastai: A Layered API for Deep Learning}},
JOURNAL = {Information},
VOLUME = {11},
YEAR = {2020},
NUMBER = {2},
ARTICLE-NUMBER = {108},
URL = {https://www.mdpi.com/2078-2489/11/2/108},
ISSN = {2078-2489},
ABSTRACT = {fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches. It aims to do both things without substantial compromises in ease of use, flexibility, or performance. This is possible thanks to a carefully layered architecture, which expresses common underlying patterns of many deep learning and data processing techniques in terms of decoupled abstractions. These abstractions can be expressed concisely and clearly by leveraging the dynamism of the underlying Python language and the flexibility of the PyTorch library. fastai includes: a new type dispatch system for Python along with a semantic type hierarchy for tensors; a GPU-optimized computer vision library which can be extended in pure Python; an optimizer which refactors out the common functionality of modern optimizers into two basic pieces, allowing optimization algorithms to be implemented in 4&ndash;5 lines of code; a novel 2-way callback system that can access any part of the data, model, or optimizer and change it at any point during training; a new data block API; and much more. We used this library to successfully create a complete deep learning course, which we were able to write more quickly than using previous approaches, and the code was more clear. The library is already in wide use in research, industry, and teaching.},
DOI = {10.3390/info11020108}
}
@INPROCEEDINGS{resnet,
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Deep Residual Learning for Image Recognition}, 
  year={2016},
  volume={},
  number={},
  pages={770-778},
  doi={10.1109/CVPR.2016.90}}

@misc{Kinetics,
  doi = {10.48550/ARXIV.1705.06950},
  
  url = {https://arxiv.org/abs/1705.06950},
  
  author = {Kay, Will and Carreira, Joao and Simonyan, Karen and Zhang, Brian and Hillier, Chloe and Vijayanarasimhan, Sudheendra and Viola, Fabio and Green, Tim and Back, Trevor and Natsev, Paul and Suleyman, Mustafa and Zisserman, Andrew},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {The Kinetics Human Action Video Dataset},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{wandb,
title = {Experiment Tracking with Weights and Biases},
year = {2020},
note = {Software available from wandb.com},
url={https://www.wandb.com/},
author = {Biewald, Lukas},
}

@misc{dropout,
  doi = {10.48550/ARXIV.1207.0580},
  
  url = {https://arxiv.org/abs/1207.0580},
  
  author = {Hinton, Geoffrey E. and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R.},
  
  keywords = {Neural and Evolutionary Computing (cs.NE), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Improving neural networks by preventing co-adaptation of feature detectors},
  
  publisher = {arXiv},
  
  year = {2012},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@InProceedings{pmlr-v48-gal16,
  title = 	 {Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning},
  author = 	 {Gal, Yarin and Ghahramani, Zoubin},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {1050--1059},
  year = 	 {2016},
  editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/gal16.pdf},
  url = 	 {https://proceedings.mlr.press/v48/gal16.html},
  abstract = 	 {Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs – extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout’s uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout’s uncertainty in deep reinforcement learning.}
}

@misc{adam,
  doi = {10.48550/ARXIV.1412.6980},
  
  url = {https://arxiv.org/abs/1412.6980},
  
  author = {Kingma, Diederik P. and Ba, Jimmy},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Adam: A Method for Stochastic Optimization},
  
  publisher = {arXiv},
  
  year = {2014},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@misc{smith2018,
  doi = {10.48550/ARXIV.1803.09820},
  
  url = {https://arxiv.org/abs/1803.09820},
  
  author = {Smith, Leslie N.},
  
  keywords = {Machine Learning (cs.LG), Computer Vision and Pattern Recognition (cs.CV), Neural and Evolutionary Computing (cs.NE), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch size, momentum, and weight decay},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@INPROCEEDINGS {labelsmoothing,
author = {C. Szegedy and V. Vanhoucke and S. Ioffe and J. Shlens and Z. Wojna},
booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title = {Rethinking the Inception Architecture for Computer Vision},
year = {2016},
volume = {},
issn = {1063-6919},
pages = {2818-2826},
keywords = {convolution;computer architecture;training;computational efficiency;computer vision;benchmark testing;computational modeling},
doi = {10.1109/CVPR.2016.308},
url = {https://doi.ieeecomputersociety.org/10.1109/CVPR.2016.308},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jun}
}
